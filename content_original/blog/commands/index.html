---
title: 'Running Tally of Commands'
author: 'Rebecca Frost-Brewer'
excerpt: 'A compilation of the commands learned in Flatiron lessons on `git`, `python`, and SQL'
date: '2022-03-05'
slug: []
categories: []
tags: []
output: html_document
---



<p>Each lesson and topic of Flatiron includes several new <code>git</code>, <code>python</code>, and SQL commands. Here, I will be compiling all those commands in one place for my reference, with a description of what the command does and a use example.</p>
<div id="bash-and-git" class="section level2">
<h2>Bash and Git</h2>
<p>+—————————————–+——————————————————+
| Bash Command | Description
+=========================================+======================================================+
| <code>cd</code> | Navigate to the directory/folder where you want to work
+—————————————–+——————————————————+
| <code>cd ~/Documents</code> | Move to user’s home directory
+—————————————–+——————————————————+
<code>pwd</code> | Print working directory (see where you’re working in bash)
+—————————————–+——————————————————+
<code>mkdir</code> | Create a new folder within your repo directory
+—————————————–+——————————————————+
<code>git init</code> | Turn current directory into a Git repository
+—————————————–+——————————————————+
<code>git clone URL</code> | Download a forked repo from your GitHub to your local computer
+—————————————–+——————————————————+
<code>git add</code> | Stage changes you’ve made so they’re ready to be committed
+—————————————–+——————————————————+
<code>git status</code> | Check out what’s going on in your repo and its files
+—————————————–+——————————————————+
<code>git remote add origin</code> | Add the link to the GitHub URL where your repository is stored online
+—————————————–+——————————————————+
<code>git commit -am "your commit message</code> | Commit added files to the repository with shortcut <code>am</code> to “add message”
+—————————————–+——————————————————+
<code>git push origin master</code> | Push/Sync changes to online version of the repo (<code>master</code> is the default branch for all Git repos)
+—————————————–+——————————————————+
<code>git branch</code> | Start a new branch within your repo - good as a “sandbox” version for messing around without fear of changing the <code>master</code>
+—————————————–+——————————————————+
<code>git checkout</code> | Navigate to a different branch
+—————————————–+——————————————————+
<code>git log</code> | Displays the history of commits for the branch you’re on
+—————————————–+——————————————————+
<code>git merge &lt;branch-to-merge&gt; -m "message"</code>| Merge a branch into the master
+—————————————–+——————————————————+
<code>ls</code> | List all the files in the current direcotry
+—————————————–+——————————————————+</p>
</div>
<div id="base-python" class="section level2">
<h2>Base Python</h2>
<p>+——————————-+—————————————————————-+
| Python Command | Description
+===============================+================================================================+
<code>! ls</code> | List the files in the current directory
+——————————-+—————————————————————-+
<code>import</code> | Load a necessary Python package/module
+——————————-+—————————————————————-+
<code>! cat</code> | Inspect/list the files of a file that was opened
+——————————-+—————————————————————-+
<code>len()</code> | Show length (number of) items/records
+——————————-+—————————————————————-+
<code>print(df)</code> | Look a dataframe’s elements
+——————————-+—————————————————————-+
<code>df.head()</code> | Show first five rows
+——————————-+—————————————————————-+
<code>df.tail()</code> | Show last five rows
+——————————-+—————————————————————-+
<code>df.info()</code> | Show summary of dataframe (columns, values, value type)
+——————————-+—————————————————————-+
<code>df.index</code> | Access index or row labels of dataframe
+——————————-+—————————————————————-+
<code>df.columns</code> | Access column labels
+——————————-+—————————————————————-+
<code>df.dtypes</code> | Access data types of all columns
+——————————-+—————————————————————-+
<code>df.shape</code> | Returns a tuple representing dimensionality (rows, columns)
+——————————-+—————————————————————-+
<code>df.iloc[#]</code> | Select row based on integer-location
+——————————-+—————————————————————-+
<code>df.loc[:,'column name']</code> | Select row based on row index and column name
+——————————-+—————————————————————-+
<code>df.map()</code> | Transforms values
+——————————-+—————————————————————-+
<code>df['column'].value_counts()</code> | Get count of records of a particular column
+——————————-+—————————————————————-+
<code>df.describe()</code> | Calculate basic summary statistics of each column
+——————————-+—————————————————————-+
<code>df['column'].mean()</code> | Calculate specific summary stat of a specific column
+——————————-+—————————————————————-+
<code>.mode()</code> | the mode of the column
+——————————-+—————————————————————-+
<code>.count()</code> | the count of the total number of entries in a column
+——————————-+—————————————————————-+
<code>.std()</code> | the standard deviation for the column
+——————————-+—————————————————————-+
<code>.var()</code> | the variance for the column
+——————————-+—————————————————————-+
<code>.sum()</code> | the sum of all values in the column
+——————————-+—————————————————————-+
<code>.cumsum()</code> | the cumulative sum, where each cell index contains the sum of all indices lower than, and including, itself.
+——————————-+—————————————————————-+
<code>df.isna()</code> | Return a matrix of boolean values (T/F) where all cells contain NaN
+——————————-+—————————————————————-+
<code>df.groupby()</code> | Aggregate function to group by a particular column
+——————————-+—————————————————————-+
<code>pd.concat()</code> | Pandas function to concatenate two or more dataframes
+——————————-+—————————————————————-+
<code>df.join()</code> | Join all records from the left table and the right table that have a matching key
+——————————-+—————————————————————-+</p>
<div id="csv" class="section level3">
<h3>CSV</h3>
<pre class="python"><code>import csv

# This code prints the first line of the CSV file
with open(csv_file_path) as csvfile:
    print(csvfile.readline())


# Print OrderedDict from first row of CSV file  - reads each row then converts to dictionary
with open(csv_file_path) as csvfile:
    reader = csv.DictReader(csvfile)
    print(next(reader))</code></pre>
</div>
<div id="json" class="section level3">
<h3>JSON</h3>
<pre class="python"><code>import json

with open(&#39;nyc_2001_campaign_finance.json&#39;) as f:
    data = json.load(f)
print(type(data))</code></pre>
<div id="investigating-the-dataset-structure" class="section level4">
<h4>Investigating the dataset structure</h4>
<pre class="python"><code># Data type of dictionary keys`
type(data[&#39;key&#39;])

print(f&quot;The overall data type is {type(data)}&quot;)
print(f&quot;The keys are {list(data.keys())}&quot;)
print(&quot;The value associated with the &#39;meta&#39; key has metadata, including all of these attributes:&quot;)
print(list(data[&#39;meta&#39;][&#39;view&#39;].keys()))
print(f&quot;The value associated with the &#39;data&#39; key is a list of {len(data[&#39;data&#39;])} records&quot;)

# Checking individual data types
for key in data[&#39;json-object&#39;].keys():
    print(key, type(data[&#39;json-object&#39;][key]))

# Each dictionary has a &#39;name key&#39;
# Use list comprehension for column_names
column_names = [column[&#39;name&#39;] for column in data[&#39;meta&#39;][&#39;view&#39;][&#39;columns&#39;]]
print(column_names)</code></pre>
</div>
</div>
</div>
<div id="intro-to-pandas-and-matplotlib" class="section level2">
<h2>Intro to <code>pandas</code> and <code>matplotlib</code></h2>
<pre class="python"><code># Import pandas using the standard alias
import pandas as pd

# Load &#39;datafile.csv&#39; as a DataFrame
df = pd.read_csv(&#39;datafile.csv&#39;)

# Group by the column business_id, then number of stars, and take the mean of stars by business id
df.groupby(&#39;business_id&#39;)[&#39;stars&#39;].mean().head()

# Drop duplicates from df
df = df.drop_duplicates()

# Concatenate three dataframes together
combined_df = pd.concat([df1, df2, df3])

# Pivot table
pivoted = grouped.pivot(index = &#39;Pclass&#39;, columns = &#39;Sex&#39;, values = &#39;Age&#39;)

# Plot
pivoted.plot(kind = &#39;barh&#39;) # Horizontal bar chart</code></pre>
<div id="world-cup-file-examples" class="section level3">
<h3>World Cup file examples</h3>
<pre class="python"><code># Select all rows of games played in Group 3 during the 1950 WC
df[(df[&#39;Year&#39;] == 1950) &amp; (df[&#39;Stage&#39;] == &#39;Group 3&#39;)]
# From the full df, &#39;year&#39; is 1950 AND &#39;stage&#39; is Group 3

# Count number of home games played by the Netherlands
neth_home = len(df[df[&#39;Home Team Name&#39;] == (&#39;Netherlands&#39;)])

# How many countries played in 1986?
wc1986 = df.loc[df[&#39;Year&#39;] == 1986]
# Create object wc1986 where the location &#39;year&#39; is 1986
print(&quot;The total number of games in 1986:&quot;, len(wc1986))

# Diaplay all records containing the string &#39;Korea&#39;
df.loc[df[&#39;Home Team Name&#39;].str.contains(&#39;Korea&#39;), &#39;Home Team Name&#39;]</code></pre>
</div>
<div id="subway-file-examples" class="section level3">
<h3>Subway file examples</h3>
<pre class="python"><code># Type out abbreviations and store as dictionary object
division_mapping = {
    &quot;IRT&quot;: &quot;Interborough Rapid Transit Company&quot;,
    &quot;IND&quot;: &quot;Independent Subway System&quot;,
    &quot;BMT&quot;: &quot;Brooklyn–Manhattan Transit Corporation&quot;,
    &quot;PTH&quot;: &quot;Port Authority Trans-Hudson (PATH)&quot;,
    &quot;SRT&quot;: &quot;Staten Island Rapid Transit&quot;,
    &quot;RIT&quot;: &quot;Roosevelt Island Tram&quot;
}

# For the column DIVISION, map the full names instead of the abbreviations
df[&#39;DIVISION&#39;].map(division_mapping)

# Rename a column, make change permanent
df.rename(columns={&#39;C/A&#39; : &#39;CONTROL_AREA&#39;}, inplace = True)

# Change type of entry of a column
df[&#39;ENTRIES&#39;] = df[&#39;ENTRIES&#39;].astype(int)

# Change date string to date format
pd.to_datetime(df[&#39;DATE&#39;], format=&#39;%m/%d/%Y&#39;).head()</code></pre>
</div>
<div id="lego-file-example" class="section level3">
<h3>Lego file example</h3>
<pre class="python"><code># Print the unique values in the review_difficulty column
df[&#39;review_difficulty&#39;].unique()</code></pre>
</div>
<div id="lambda-functions" class="section level3">
<h3>Lambda functions</h3>
<pre class="python"><code># For the text column, for each item, split each word, and list the length, but show only first five rows
df[&#39;text&#39;].map(lambda review_text: len(review_text.split())).head()

# Sorting by last name
names = [&#39;Miriam Marks&#39;,&#39;Sidney Baird&#39;,&#39;Elaine Barrera&#39;,&#39;Eddie Reeves&#39;,&#39;Marley Beard&#39;,
         &#39;Jaiden Liu&#39;,&#39;Bethany Martin&#39;,&#39;Stephen Rios&#39;,&#39;Audrey Mayer&#39;,&#39;Kameron Davidson&#39;,
&#39;Teagan Bennett&#39;]

# Split/identify the second word, sort by the second word
sorted(names, key=lambda x: x.split()[1])

# Find the average number of words for a review
df[&#39;text&#39;].map(lambda x: len(x.split())).mean()</code></pre>
</div>
<div id="titanic-file-examples" class="section level3">
<h3>Titanic file examples</h3>
<pre class="python"><code># Print the percentage of null values in the column &#39;Cabin
# Print the number of unique cabin values
print(&#39;Percentage of Null Cabin Values:&#39;, len(df[df.Cabin.isna()])/ len(df))
print(&#39;Number of Unique Cabin Values:&#39;, df.Cabin.nunique())

# Replace missing values with a summary statistic
df[&#39;Age&#39;] = df[&#39;Age&#39;].fillna(value=df[&#39;Age&#39;].median)

# Drop rows that contain missing values
df = df.dropna()

# Find summary statistics of grouped columns
df.groupby([&#39;Sex&#39;, &#39;Pclass&#39;]).mean()</code></pre>
</div>
</div>
<div id="sql" class="section level2">
<h2>SQL</h2>
<table>
<thead>
<tr class="header">
<th>SQL Command</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>SELECT</code></td>
<td>Select which columns</td>
</tr>
<tr class="even">
<td><code>FROM</code></td>
<td>Select from which table</td>
</tr>
<tr class="odd">
<td><code>pd.read_sql("", conn)</code></td>
<td>Executing a SQL query using pandas</td>
</tr>
<tr class="even">
<td><code>WHERE</code></td>
<td>Rows match a particular condition</td>
</tr>
<tr class="odd">
<td><code>CAST</code></td>
<td>Change record to a particular value type</td>
</tr>
<tr class="even">
<td><code>AS</code></td>
<td>Create an alias to rename a column</td>
</tr>
<tr class="odd">
<td><code>ORDER BY</code></td>
<td>Order query result</td>
</tr>
<tr class="even">
<td><code>ASC</code></td>
<td>Ascending</td>
</tr>
<tr class="odd">
<td><code>DESC</code></td>
<td>Descending</td>
</tr>
<tr class="even">
<td><code>LIMIT</code></td>
<td>Specify a certain number of results</td>
</tr>
<tr class="odd">
<td><code>HAVING</code></td>
<td>Filters conditions after <code>GROUP BY</code></td>
</tr>
</tbody>
</table>
<div id="conditional-sql-operators" class="section level3">
<h3>Conditional SQL Operators</h3>
<ul>
<li><code>!=</code> (“not equal to”)
<ul>
<li>Similar to <code>not</code> combined with <code>==</code> in Python</li>
</ul></li>
<li><code>&gt;</code> (“greater than”)
<ul>
<li>Similar to <code>&gt;</code> in Python</li>
</ul></li>
<li><code>&gt;=</code> (“greater than or equal to”)
<ul>
<li>Similar to <code>&gt;=</code> in Python</li>
</ul></li>
<li><code>&lt;</code> (“less than”)
<ul>
<li>Similar to <code>&lt;</code> in Python</li>
</ul></li>
<li><code>&lt;=</code> (“less than or equal to”)
<ul>
<li>Similar to <code>&lt;=</code> in Python</li>
</ul></li>
<li><code>AND</code>
<ul>
<li>Similar to <code>and</code> in Python</li>
</ul></li>
<li><code>OR</code>
<ul>
<li>Similar to <code>or</code> in Python</li>
</ul></li>
<li><code>BETWEEN</code>
<ul>
<li>Similar to placing a value between two values with <code>&lt;=</code> and <code>and</code> in Python, e.g. <code>(2 &lt;= x) and (x &lt;= 5)</code></li>
</ul></li>
<li><code>IN</code>
<ul>
<li>Similar to <code>in</code> in Python</li>
</ul></li>
<li><code>LIKE</code>
<ul>
<li>Uses wildcards to find similar strings. No direct equivalent in Python, but similar to some Bash terminal commands.</li>
</ul></li>
</ul>
</div>
<div id="sql-examples" class="section level3">
<h3>SQL Examples</h3>
<pre class="python"><code>import sqlite3 
conn = sqlite3.connect(&#39;data.sqlite&#39;) # Create a connection the SQL database

# Select all columns from the employees database
pd.read_sql(&quot;&quot;&quot;
SELECT *
  FROM employees;
&quot;&quot;&quot;, conn)

# Select the lastName and firstName columns from the employee database, show first five rows
pd.read_sql(&quot;&quot;&quot;
SELECT lastName, firstName
  FROM employees;
&quot;&quot;&quot;, conn).head()

# Select firstName, but make an alias (rename the column) &#39;name&#39;, from employees db
pd.read_sql(&quot;&quot;&quot;
SELECT firstName AS name
  FROM employees;
&quot;&quot;&quot;, conn).head()


pd.read_sql(&quot;&quot;&quot;
SELECT firstName, lastName, jobTitle,
       CASE
       WHEN jobTitle = &quot;Sales Rep&quot; THEN &quot;Sales Rep&quot;
       ELSE &quot;Not Sales Rep&quot;
       END AS role
  FROM employees;
&quot;&quot;&quot;, conn).head(10)

# Return the length (number) of character in the string firstName
pd.read_sql(&quot;&quot;&quot;
SELECT length(firstName) AS name_length
  FROM employees;
&quot;&quot;&quot;, conn).head()

# Use CAST to return integers instead of decimals
pd.read_sql(&quot;&quot;&quot;
SELECT CAST(round(priceEach) AS INTEGER) AS rounded_price_int
  FROM orderDetails;
&quot;&quot;&quot;, conn)

# Perform math operations
pd.read_sql(&quot;&quot;&quot;
SELECT priceEach * quantityOrdered AS total_price
  FROM orderDetails;
&quot;&quot;&quot;, conn)

# Split date strings into sub-parts
pd.read_sql(&quot;&quot;&quot;
SELECT orderDate,
       strftime(&quot;%m&quot;, orderDate) AS month,
       strftime(&quot;%Y&quot;, orderDate) AS year,
       strftime(&quot;%d&quot;, orderDate) AS day
  FROM orders;
&quot;&quot;&quot;, conn)

# Using WHERE
pd.read_sql(&quot;&quot;&quot;
SELECT *
  FROM employees
 WHERE lastName = &quot;Patterson&quot;;
&quot;&quot;&quot;, conn)

# Based on string conditions
pd.read_sql(&quot;&quot;&quot;
SELECT *, length(firstName) AS name_length
  FROM employees
 WHERE name_length = 5;
&quot;&quot;&quot;, conn)

# Based on value, rounded
pd.read_sql(&quot;&quot;&quot;
SELECT *, CAST(round(priceEach) AS INTEGER) AS rounded_price_int
  FROM orderDetails
 WHERE rounded_price_int = 30;
&quot;&quot;&quot;, conn)

# Select all columns for planets that have at least one moon and a mass less than 1.00
pd.read_sql(&quot;&quot;&quot;
SELECT *
  FROM planets
 WHERE num_of_moons &gt;= 1
   AND mass &lt; 1.00;
&quot;&quot;&quot;, conn)

# Select the name and color of planets that have a color containing the string &quot;blue&quot;
pd.read_sql(&quot;&quot;&quot;
SELECT name, color
  FROM planets
 WHERE color LIKE &quot;%blue%&quot;;
&quot;&quot;&quot;, conn)

# Return 10 newest orders not been shipped, not been canceled
pd.read_sql(&quot;&quot;&quot;
SELECT *
  FROM orders
 WHERE shippedDate = &quot;&quot;
   AND status != &quot;Cancelled&quot;
 ORDER BY orderDate DESC
 LIMIT 10;
&quot;&quot;&quot;, conn)</code></pre>
</div>
</div>
